// lib/agents/routing/router.ts

import { intentClassifier, ClassificationResult } from './intent-classifier';
import { knowledgeBase, SystemDocument } from '../knowledge-base/system-knowledge';
import { llmClient } from '../llm/llm-client';

export interface AgentResponse {
  content: string;
  source: 'system' | 'llm' | 'hybrid' | 'greeting';
  confidence: number;
  intent: string;
  references?: SystemDocument[];
  suggestions: string[];
}

export class IntelligentRouter {
  async route(query: string, context?: any): Promise<AgentResponse> {
    // 1. Clasificar intenciÃ³n
    const classification = intentClassifier.classify(query);
    console.log('ğŸ¯ Intent:', classification.intent, '| shouldUseLLM:', classification.shouldUseLLM);
    
    // 2. Saludo
    if (classification.intent === 'greeting') {
      return this.handleGreeting(context);
    }

    // 3. Si el clasificador dice NO usar LLM â†’ usar base local SIN verificar relevancia
    if (!classification.shouldUseLLM) {
      console.log('ğŸ“š Usando base de conocimiento local...');
      const knowledgeResults = await knowledgeBase.search(query);
      
      if (knowledgeResults.length > 0) {
        console.log('âœ… Encontrado:', knowledgeResults[0].title);
        return this.buildSystemResponse(knowledgeResults, classification);
      } else {
        console.log('âš ï¸ No encontrado en base local, usando LLM...');
      }
    }

    // 4. Usar LLM
    console.log('ğŸ¤– Usando LLM...');
    return this.buildLLMResponse(query, classification);
  }

  private handleGreeting(context?: any): AgentResponse {
    const tenantName = context?.tenant_name || 'NADAKKI Demo';
    return {
      content: `Â¡Hola! ğŸ‘‹ Soy el **NADAKKI AI Copilot**.

EstÃ¡s en **${tenantName}**. Puedo ayudarte con:

- **Workflows** - Los 10 workflows de marketing
- **Agentes** - Agentes de IA especializados
- **Tutoriales** - GuÃ­as paso a paso
- **Preguntas generales** - Marketing y estrategia

Â¿En quÃ© puedo ayudarte?`,
      source: 'greeting',
      confidence: 1,
      intent: 'greeting',
      suggestions: [
        'Â¿CÃ³mo funciona Campaign Optimization?',
        'ExplÃ­came los workflows',
        'Â¿CÃ³mo ejecuto un workflow?'
      ]
    };
  }

  private buildSystemResponse(
    results: SystemDocument[],
    classification: ClassificationResult
  ): AgentResponse {
    const primary = results[0];
    
    let content = `**${primary.title}**\n\n${primary.content}`;
    
    if (results.length > 1) {
      content += `\n\n---\n**Relacionado:**`;
      results.slice(1, 3).forEach(doc => {
        content += `\nâ€¢ ${doc.title}`;
      });
    }

    return {
      content,
      source: 'system',
      confidence: 0.95,
      intent: classification.intent,
      references: results,
      suggestions: [
        'Â¿CÃ³mo ejecuto este workflow?',
        'Â¿QuÃ© otros workflows hay?',
        'Â¿QuÃ© agentes tiene?'
      ]
    };
  }

  private async buildLLMResponse(
    query: string,
    classification: ClassificationResult
  ): Promise<AgentResponse> {
    try {
      const llmResponse = await llmClient.generate({
        prompt: query,
        maxTokens: 1024,
        temperature: 0.7
      });

      return {
        content: llmResponse.content,
        source: 'llm',
        confidence: 0.85,
        intent: classification.intent,
        suggestions: [
          'Â¿CÃ³mo aplico esto en NADAKKI?',
          'ExplÃ­came los workflows',
          'Â¿QuÃ© mÃ¡s puedo hacer?'
        ]
      };
    } catch (error) {
      console.error('âŒ LLM Error:', error);
      return {
        content: 'No pude procesar tu pregunta. Â¿PodrÃ­as reformularla?',
        source: 'system',
        confidence: 0.3,
        intent: 'unknown',
        suggestions: ['ExplÃ­came los workflows', 'Â¿QuÃ© puedo hacer?']
      };
    }
  }
}

export const router = new IntelligentRouter();